import * as faceapi from 'face-api.js';

let modelsLoaded = false;

/**
 * Load face-api.js models
 * ∆Øu ti√™n load t·ª´ local, n·∫øu kh√¥ng c√≥ th√¨ fallback sang CDN
 */
export const loadFaceModels = async () => {
  if (modelsLoaded) {
    return true;
  }

  const LOCAL_MODEL_URL = '/models';
  const CDN_MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model';

  // Th·ª≠ load t·ª´ local tr∆∞·ªõc (offline)
  try {
    console.log('[Face Detection] ƒêang t·∫£i models t·ª´ local (offline)...');
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(LOCAL_MODEL_URL),
      faceapi.nets.faceLandmark68Net.loadFromUri(LOCAL_MODEL_URL),
    ]);

    modelsLoaded = true;
    console.log('[Face Detection] ‚úì Models ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ local (offline)');
    return true;
  } catch (localError) {
    console.warn('[Face Detection] ‚ö† Kh√¥ng t√¨m th·∫•y models ·ªü local, ƒëang fallback sang CDN...');
    console.warn('[Face Detection] L·ªói local:', localError.message);
    
    // Fallback: th·ª≠ load t·ª´ CDN
    try {
      console.log('[Face Detection] ƒêang t·∫£i models t·ª´ CDN...');
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(CDN_MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(CDN_MODEL_URL),
      ]);

      modelsLoaded = true;
      console.log('[Face Detection] ‚úì Models ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ CDN (fallback)');
      console.log('[Face Detection] üí° Tip: T·∫£i models v·ªÅ local ƒë·ªÉ t·∫£i nhanh h∆°n. Ch·∫°y: ./download_face_models.sh');
      return true;
    } catch (cdnError) {
      console.error('[Face Detection] ‚úó Kh√¥ng th·ªÉ t·∫£i models t·ª´ c·∫£ local v√† CDN');
      console.error('[Face Detection] L·ªói CDN:', cdnError.message);
      return false;
    }
  }
};

/**
 * Detect face trong ·∫£nh
 * @param {File|string} imageFile - File ·∫£nh ho·∫∑c data URL
 * @returns {Promise<faceapi.WithFaceLandmarks<faceapi.WithFaceDetection<faceapi.FaceDetection>, faceapi.FaceLandmarks68>[]>} M·∫£ng c√°c khu√¥n m·∫∑t ƒë∆∞·ª£c detect
 */
export const detectFace = async (imageFile) => {
  try {
    // ƒê·∫£m b·∫£o models ƒë√£ ƒë∆∞·ª£c load
    const loaded = await loadFaceModels();
    if (!loaded) {
      throw new Error('Kh√¥ng th·ªÉ load face detection models');
    }

    // T·∫°o image element t·ª´ file
    let image;
    if (imageFile instanceof File) {
      // Chuy·ªÉn File th√†nh data URL r·ªìi load image
      const dataUrl = await new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = () => resolve(reader.result);
        reader.onerror = reject;
        reader.readAsDataURL(imageFile);
      });
      image = await faceapi.fetchImage(dataUrl);
    } else if (typeof imageFile === 'string') {
      // N·∫øu l√† data URL ho·∫∑c URL
      image = await faceapi.fetchImage(imageFile);
    } else {
      throw new Error('Invalid image file type');
    }

    // Detect face v·ªõi landmarks
    const detections = await faceapi
      .detectAllFaces(image, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks();

    return detections;
  } catch (error) {
    console.error('Error detecting face:', error);
    throw error;
  }
};

/**
 * Crop ·∫£nh c·∫≠n m·∫∑t v·ªõi padding
 * @param {File|string} imageFile - File ·∫£nh g·ªëc
 * @param {faceapi.WithFaceLandmarks} detection - K·∫øt qu·∫£ detect face
 * @param {number} padding - Padding xung quanh m·∫∑t (t·ª∑ l·ªá, default: 0.3 = 30%)
 * @returns {Promise<File>} File ·∫£nh ƒë√£ ƒë∆∞·ª£c crop
 */
export const cropFaceImage = async (imageFile, detection, padding = 0.3) => {
  return new Promise((resolve, reject) => {
    try {
      // T·∫°o image element
      const img = new Image();
      
      img.onload = () => {
        try {
          const box = detection.detection.box;
          
          // T√≠nh to√°n v√πng crop v·ªõi padding
          const paddingX = box.width * padding;
          const paddingY = box.height * padding;
          
          const x = Math.max(0, box.x - paddingX);
          const y = Math.max(0, box.y - paddingY);
          const width = Math.min(img.width - x, box.width + paddingX * 2);
          const height = Math.min(img.height - y, box.height + paddingY * 2);
          
          // T·∫°o canvas ƒë·ªÉ crop
          const canvas = document.createElement('canvas');
          canvas.width = width;
          canvas.height = height;
          const ctx = canvas.getContext('2d');
          
          // V·∫Ω ph·∫ßn ·∫£nh c·∫ßn crop l√™n canvas
          ctx.drawImage(img, x, y, width, height, 0, 0, width, height);
          
          // Chuy·ªÉn canvas th√†nh blob r·ªìi th√†nh File
          canvas.toBlob((blob) => {
            if (!blob) {
              reject(new Error('Kh√¥ng th·ªÉ t·∫°o ·∫£nh ƒë√£ crop'));
              return;
            }
            
            // T·∫°o File t·ª´ blob
            const croppedFile = new File([blob], imageFile.name || 'cropped-face.jpg', {
              type: imageFile.type || 'image/jpeg',
              lastModified: Date.now()
            });
            
            resolve(croppedFile);
          }, imageFile.type || 'image/jpeg', 0.95);
        } catch (error) {
          reject(error);
        }
      };
      
      img.onerror = () => {
        reject(new Error('Kh√¥ng th·ªÉ load ·∫£nh'));
      };
      
      // Set source cho image
      if (imageFile instanceof File) {
        const reader = new FileReader();
        reader.onload = (e) => {
          img.src = e.target.result;
        };
        reader.onerror = () => {
          reject(new Error('Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh'));
        };
        reader.readAsDataURL(imageFile);
      } else if (typeof imageFile === 'string') {
        img.src = imageFile;
      } else {
        reject(new Error('Invalid image file type'));
      }
    } catch (error) {
      reject(error);
    }
  });
};

/**
 * Validate v√† crop ·∫£nh khu√¥n m·∫∑t
 * @param {File} imageFile - File ·∫£nh c·∫ßn validate v√† crop
 * @returns {Promise<{success: boolean, file?: File, error?: string, detection?: any}>}
 */
export const validateAndCropFace = async (imageFile) => {
  try {
    // ƒê·∫£m b·∫£o models ƒë√£ ƒë∆∞·ª£c load
    const loaded = await loadFaceModels();
    if (!loaded) {
      return {
        success: false,
        error: 'Kh√¥ng th·ªÉ t·∫£i models nh·∫≠n di·ªán khu√¥n m·∫∑t. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet v√† th·ª≠ l·∫°i.'
      };
    }

    // Detect face
    console.log('[Face Detection] ƒêang nh·∫≠n di·ªán khu√¥n m·∫∑t...');
    const detections = await detectFace(imageFile);
    
    if (!detections || detections.length === 0) {
      console.warn('[Face Detection] Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh');
      return {
        success: false,
        error: '‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh.\n\nVui l√≤ng:\n‚Ä¢ Ch·ªçn ·∫£nh c√≥ khu√¥n m·∫∑t r√µ r√†ng, ch·ª•p ch√≠nh di·ªán\n‚Ä¢ ƒê·∫£m b·∫£o khu√¥n m·∫∑t kh√¥ng b·ªã che khu·∫•t\n‚Ä¢ Tr√°nh ·∫£nh qu√° t·ªëi ho·∫∑c qu√° s√°ng\n‚Ä¢ Tr√°nh ·∫£nh b·ªã m·ªù ho·∫∑c kh√¥ng r√µ n√©t'
      };
    }
    
    if (detections.length > 1) {
      console.warn(`[Face Detection] T√¨m th·∫•y ${detections.length} khu√¥n m·∫∑t trong ·∫£nh`);
      return {
        success: false,
        error: `‚ùå ·∫¢nh c√≥ ${detections.length} khu√¥n m·∫∑t.\n\nVui l√≤ng ch·ªçn ·∫£nh ch·ªâ c√≥ m·ªôt khu√¥n m·∫∑t ƒë·ªÉ ph√¢n t√≠ch ch√≠nh x√°c.`
      };
    }
    
    console.log('[Face Detection] ‚úì ƒê√£ t√¨m th·∫•y 1 khu√¥n m·∫∑t, ƒëang c·∫Øt ·∫£nh c·∫≠n m·∫∑t...');
    
    // Crop ·∫£nh c·∫≠n m·∫∑t
    const croppedFile = await cropFaceImage(imageFile, detections[0]);
    
    console.log('[Face Detection] ‚úì ƒê√£ c·∫Øt ·∫£nh c·∫≠n m·∫∑t th√†nh c√¥ng');
    
    return {
      success: true,
      file: croppedFile,
      detection: detections[0]
    };
  } catch (error) {
    console.error('[Face Detection] ‚úó L·ªói khi x·ª≠ l√Ω ·∫£nh:', error);
    
    // X·ª≠ l√Ω c√°c lo·∫°i l·ªói c·ª• th·ªÉ
    let errorMessage = 'C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i.';
    
    if (error.message) {
      if (error.message.includes('load face detection models')) {
        errorMessage = '‚ùå Kh√¥ng th·ªÉ t·∫£i models nh·∫≠n di·ªán khu√¥n m·∫∑t.\n\nVui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet v√† th·ª≠ l·∫°i.';
      } else if (error.message.includes('Invalid image file type')) {
        errorMessage = '‚ùå ƒê·ªãnh d·∫°ng ·∫£nh kh√¥ng h·ª£p l·ªá.\n\nVui l√≤ng ch·ªçn file ·∫£nh (JPG, JPEG, PNG, WEBP).';
      } else if (error.message.includes('load ·∫£nh') || error.message.includes('ƒë·ªçc file')) {
        errorMessage = '‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh.\n\nVui l√≤ng ki·ªÉm tra file ·∫£nh c√≥ b·ªã h·ªèng kh√¥ng v√† th·ª≠ l·∫°i.';
      } else {
        errorMessage = `‚ùå L·ªói: ${error.message}\n\nVui l√≤ng th·ª≠ l·∫°i ho·∫∑c ch·ªçn ·∫£nh kh√°c.`;
      }
    }
    
    return {
      success: false,
      error: errorMessage
    };
  }
};

