// Suppress TensorFlow.js warnings v·ªÅ backend ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω
// ƒêi·ªÅu n√†y x·∫£y ra khi module ƒë∆∞·ª£c load nhi·ªÅu l·∫ßn do code splitting
const originalWarn = console.warn;
const originalError = console.error;
let isSuppressingWarnings = false;

const suppressTensorFlowWarnings = () => {
  if (isSuppressingWarnings) return;
  isSuppressingWarnings = true;

  console.warn = (...args) => {
    const message = args[0]?.toString() || '';
    // Suppress c√°c warning v·ªÅ backend ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω
    if (
      message.includes('backend was already registered') ||
      message.includes('Platform browser has already been set')
    ) {
      return; // Kh√¥ng log warning n√†y
    }
    originalWarn.apply(console, args);
  };
};

// Suppress warnings tr∆∞·ªõc khi import face-api
suppressTensorFlowWarnings();

// Dynamic import ƒë·ªÉ tr√°nh load ngay khi module ƒë∆∞·ª£c import
let faceapi = null;
let faceapiPromise = null;

const getFaceApi = async () => {
  if (faceapi) return faceapi;
  if (faceapiPromise) return faceapiPromise;
  
  faceapiPromise = import('face-api.js').then(module => {
    faceapi = module;
    return faceapi;
  });
  
  return faceapiPromise;
};

let modelsLoaded = false;

/**
 * Ki·ªÉm tra xem file model c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c kh√¥ng
 */
const checkModelFileAccess = async (baseUrl, fileName) => {
  try {
    const response = await fetch(`${baseUrl}/${fileName}`, { method: 'HEAD' });
    return response.ok;
  } catch (error) {
    return false;
  }
};

/**
 * Load face-api.js models
 * ∆Øu ti√™n load t·ª´ local, n·∫øu kh√¥ng c√≥ th√¨ fallback sang CDN
 */
export const loadFaceModels = async () => {
  if (modelsLoaded) {
    return true;
  }

  // ƒê·∫£m b·∫£o face-api ƒë√£ ƒë∆∞·ª£c load
  const faceapiModule = await getFaceApi();
  const LOCAL_MODEL_URL = '/models';
  const CDN_MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model';
  
  // Ki·ªÉm tra xem file models c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c kh√¥ng
  const manifestExists = await checkModelFileAccess(LOCAL_MODEL_URL, 'tiny_face_detector_model-weights_manifest.json');
  if (!manifestExists) {
    console.warn('[Face Detection] ‚ö† Kh√¥ng t√¨m th·∫•y file manifest ·ªü local, ƒëang fallback sang CDN...');
  }

  // Th·ª≠ load t·ª´ local tr∆∞·ªõc (offline)
  try {
    console.log('[Face Detection] ƒêang t·∫£i models t·ª´ local (offline)...');
    console.log('[Face Detection] Path:', LOCAL_MODEL_URL);
    
    // Verify file size tr∆∞·ªõc khi load ƒë·ªÉ tr√°nh l·ªói tensor
    try {
      const manifestResponse = await fetch(`${LOCAL_MODEL_URL}/tiny_face_detector_model-weights_manifest.json`);
      if (!manifestResponse.ok) {
        throw new Error('Kh√¥ng th·ªÉ truy c·∫≠p file manifest');
      }
      const shardResponse = await fetch(`${LOCAL_MODEL_URL}/tiny_face_detector_model-shard1`, { method: 'HEAD' });
      if (!shardResponse.ok) {
        throw new Error('Kh√¥ng th·ªÉ truy c·∫≠p file shard');
      }
      const contentLength = shardResponse.headers.get('content-length');
      if (contentLength && parseInt(contentLength) < 180000) {
        console.warn('[Face Detection] ‚ö† File shard c√≥ v·∫ª b·ªã h·ªèng (k√≠ch th∆∞·ªõc:', contentLength, 'bytes), ƒëang fallback sang CDN...');
        throw new Error('File model b·ªã h·ªèng ho·∫∑c kh√¥ng ƒë·∫ßy ƒë·ªß');
      }
    } catch (verifyError) {
      console.warn('[Face Detection] ‚ö† L·ªói khi verify file models:', verifyError.message);
      throw verifyError;
    }
    
    // Load t·ª´ng model ri√™ng ƒë·ªÉ d·ªÖ debug
    console.log('[Face Detection] ƒêang t·∫£i Tiny Face Detector...');
    await faceapiModule.nets.tinyFaceDetector.loadFromUri(LOCAL_MODEL_URL);
    console.log('[Face Detection] ‚úì Tiny Face Detector ƒë√£ t·∫£i xong');
    
    console.log('[Face Detection] ƒêang t·∫£i Face Landmark 68...');
    await faceapiModule.nets.faceLandmark68Net.loadFromUri(LOCAL_MODEL_URL);
    console.log('[Face Detection] ‚úì Face Landmark 68 ƒë√£ t·∫£i xong');

    modelsLoaded = true;
    console.log('[Face Detection] ‚úì Models ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ local (offline)');
    return true;
  } catch (localError) {
    console.warn('[Face Detection] ‚ö† Kh√¥ng t√¨m th·∫•y models ·ªü local, ƒëang fallback sang CDN...');
    console.warn('[Face Detection] L·ªói local:', localError.message);
    console.warn('[Face Detection] Stack:', localError.stack);
    
    // Fallback: th·ª≠ load t·ª´ CDN
    try {
      console.log('[Face Detection] ƒêang t·∫£i models t·ª´ CDN...');
      console.log('[Face Detection] CDN URL:', CDN_MODEL_URL);
      
      // Ki·ªÉm tra xem c√≥ th·ªÉ truy c·∫≠p CDN kh√¥ng (CORS check)
      try {
        const testResponse = await fetch(`${CDN_MODEL_URL}/tiny_face_detector_model-weights_manifest.json`, { 
          method: 'HEAD',
          mode: 'cors'
        });
        if (!testResponse.ok) {
          throw new Error(`CDN kh√¥ng th·ªÉ truy c·∫≠p: ${testResponse.status} ${testResponse.statusText}`);
        }
        console.log('[Face Detection] ‚úì CDN c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c');
      } catch (corsError) {
        console.warn('[Face Detection] ‚ö† CORS ho·∫∑c network error khi ki·ªÉm tra CDN:', corsError.message);
        // V·∫´n th·ª≠ load, c√≥ th·ªÉ l√† CORS warning nh∆∞ng v·∫´n load ƒë∆∞·ª£c
      }
      
      // Load t·ª´ng model ri√™ng ƒë·ªÉ d·ªÖ debug
      console.log('[Face Detection] ƒêang t·∫£i Tiny Face Detector t·ª´ CDN...');
      await faceapiModule.nets.tinyFaceDetector.loadFromUri(CDN_MODEL_URL);
      console.log('[Face Detection] ‚úì Tiny Face Detector ƒë√£ t·∫£i xong t·ª´ CDN');
      
      console.log('[Face Detection] ƒêang t·∫£i Face Landmark 68 t·ª´ CDN...');
      await faceapiModule.nets.faceLandmark68Net.loadFromUri(CDN_MODEL_URL);
      console.log('[Face Detection] ‚úì Face Landmark 68 ƒë√£ t·∫£i xong t·ª´ CDN');

      modelsLoaded = true;
      console.log('[Face Detection] ‚úì Models ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ CDN (fallback)');
      console.log('[Face Detection] üí° Tip: T·∫£i models v·ªÅ local ƒë·ªÉ t·∫£i nhanh h∆°n. Ch·∫°y: ./download_face_models.sh');
      return true;
    } catch (cdnError) {
      console.error('[Face Detection] ‚úó Kh√¥ng th·ªÉ t·∫£i models t·ª´ c·∫£ local v√† CDN');
      console.error('[Face Detection] L·ªói CDN:', cdnError.message);
      console.error('[Face Detection] Stack CDN:', cdnError.stack);
      
      // Th√¥ng b√°o chi ti·∫øt v·ªÅ l·ªói
      if (cdnError.message.includes('CORS') || cdnError.message.includes('Failed to fetch')) {
        console.error('[Face Detection] ‚ö† C√≥ th·ªÉ l√† v·∫•n ƒë·ªÅ CORS ho·∫∑c network. Ki·ªÉm tra:');
        console.error('[Face Detection]   1. Content Security Policy (CSP) c√≥ block CDN kh√¥ng?');
        console.error('[Face Detection]   2. Network c√≥ ch·∫∑n external requests kh√¥ng?');
        console.error('[Face Detection]   3. Mixed content (HTTP/HTTPS) issues?');
      }
      
      return false;
    }
  }
};

/**
 * Detect face trong ·∫£nh
 * @param {File|string} imageFile - File ·∫£nh ho·∫∑c data URL
 * @returns {Promise<faceapi.WithFaceLandmarks<faceapi.WithFaceDetection<faceapi.FaceDetection>, faceapi.FaceLandmarks68>[]>} M·∫£ng c√°c khu√¥n m·∫∑t ƒë∆∞·ª£c detect
 */
export const detectFace = async (imageFile) => {
  try {
    // ƒê·∫£m b·∫£o models ƒë√£ ƒë∆∞·ª£c load
    const loaded = await loadFaceModels();
    if (!loaded) {
      throw new Error('Kh√¥ng th·ªÉ load face detection models');
    }

    // ƒê·∫£m b·∫£o face-api ƒë√£ ƒë∆∞·ª£c load
    const faceapiModule = await getFaceApi();

    // T·∫°o image element t·ª´ file
    let image;
    if (imageFile instanceof File) {
      // Chuy·ªÉn File th√†nh data URL r·ªìi load image
      const dataUrl = await new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = () => resolve(reader.result);
        reader.onerror = reject;
        reader.readAsDataURL(imageFile);
      });
      image = await faceapiModule.fetchImage(dataUrl);
    } else if (typeof imageFile === 'string') {
      // N·∫øu l√† data URL ho·∫∑c URL
      image = await faceapiModule.fetchImage(imageFile);
    } else {
      throw new Error('Invalid image file type');
    }

    // Detect face v·ªõi landmarks
    const detections = await faceapiModule
      .detectAllFaces(image, new faceapiModule.TinyFaceDetectorOptions())
      .withFaceLandmarks();

    return detections;
  } catch (error) {
    console.error('Error detecting face:', error);
    throw error;
  }
};

/**
 * Crop ·∫£nh c·∫≠n m·∫∑t v·ªõi padding
 * @param {File|string} imageFile - File ·∫£nh g·ªëc
 * @param {faceapi.WithFaceLandmarks} detection - K·∫øt qu·∫£ detect face
 * @param {number} padding - Padding xung quanh m·∫∑t (t·ª∑ l·ªá, default: 0.3 = 30%)
 * @returns {Promise<File>} File ·∫£nh ƒë√£ ƒë∆∞·ª£c crop
 */
export const cropFaceImage = async (imageFile, detection, padding = 0.3) => {
  return new Promise((resolve, reject) => {
    try {
      // T·∫°o image element
      const img = new Image();
      
      img.onload = () => {
        try {
          const box = detection.detection.box;
          
          // T√≠nh to√°n v√πng crop v·ªõi padding
          const paddingX = box.width * padding;
          const paddingY = box.height * padding;
          
          const x = Math.max(0, box.x - paddingX);
          const y = Math.max(0, box.y - paddingY);
          const width = Math.min(img.width - x, box.width + paddingX * 2);
          const height = Math.min(img.height - y, box.height + paddingY * 2);
          
          // T·∫°o canvas ƒë·ªÉ crop
          const canvas = document.createElement('canvas');
          canvas.width = width;
          canvas.height = height;
          const ctx = canvas.getContext('2d');
          
          // V·∫Ω ph·∫ßn ·∫£nh c·∫ßn crop l√™n canvas
          ctx.drawImage(img, x, y, width, height, 0, 0, width, height);
          
          // Chuy·ªÉn canvas th√†nh blob r·ªìi th√†nh File
          canvas.toBlob((blob) => {
            if (!blob) {
              reject(new Error('Kh√¥ng th·ªÉ t·∫°o ·∫£nh ƒë√£ crop'));
              return;
            }
            
            // T·∫°o File t·ª´ blob
            const croppedFile = new File([blob], imageFile.name || 'cropped-face.jpg', {
              type: imageFile.type || 'image/jpeg',
              lastModified: Date.now()
            });
            
            resolve(croppedFile);
          }, imageFile.type || 'image/jpeg', 0.95);
        } catch (error) {
          reject(error);
        }
      };
      
      img.onerror = () => {
        reject(new Error('Kh√¥ng th·ªÉ load ·∫£nh'));
      };
      
      // Set source cho image
      if (imageFile instanceof File) {
        const reader = new FileReader();
        reader.onload = (e) => {
          img.src = e.target.result;
        };
        reader.onerror = () => {
          reject(new Error('Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh'));
        };
        reader.readAsDataURL(imageFile);
      } else if (typeof imageFile === 'string') {
        img.src = imageFile;
      } else {
        reject(new Error('Invalid image file type'));
      }
    } catch (error) {
      reject(error);
    }
  });
};

/**
 * Validate v√† crop ·∫£nh khu√¥n m·∫∑t
 * @param {File} imageFile - File ·∫£nh c·∫ßn validate v√† crop
 * @returns {Promise<{success: boolean, file?: File, error?: string, detection?: any}>}
 */
export const validateAndCropFace = async (imageFile) => {
  try {
    // ƒê·∫£m b·∫£o models ƒë√£ ƒë∆∞·ª£c load
    const loaded = await loadFaceModels();
    if (!loaded) {
      return {
        success: false,
        error: 'Kh√¥ng th·ªÉ t·∫£i models nh·∫≠n di·ªán khu√¥n m·∫∑t. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet v√† th·ª≠ l·∫°i.'
      };
    }

    // Detect face
    console.log('[Face Detection] ƒêang nh·∫≠n di·ªán khu√¥n m·∫∑t...');
    const detections = await detectFace(imageFile);
    
    if (!detections || detections.length === 0) {
      console.warn('[Face Detection] Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh');
      return {
        success: false,
        error: '‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh.\n\nVui l√≤ng:\n‚Ä¢ Ch·ªçn ·∫£nh c√≥ khu√¥n m·∫∑t r√µ r√†ng, ch·ª•p ch√≠nh di·ªán\n‚Ä¢ ƒê·∫£m b·∫£o khu√¥n m·∫∑t kh√¥ng b·ªã che khu·∫•t\n‚Ä¢ Tr√°nh ·∫£nh qu√° t·ªëi ho·∫∑c qu√° s√°ng\n‚Ä¢ Tr√°nh ·∫£nh b·ªã m·ªù ho·∫∑c kh√¥ng r√µ n√©t'
      };
    }
    
    if (detections.length > 1) {
      console.warn(`[Face Detection] T√¨m th·∫•y ${detections.length} khu√¥n m·∫∑t trong ·∫£nh`);
      return {
        success: false,
        error: `‚ùå ·∫¢nh c√≥ ${detections.length} khu√¥n m·∫∑t.\n\nVui l√≤ng ch·ªçn ·∫£nh ch·ªâ c√≥ m·ªôt khu√¥n m·∫∑t ƒë·ªÉ ph√¢n t√≠ch ch√≠nh x√°c.`
      };
    }
    
    console.log('[Face Detection] ‚úì ƒê√£ t√¨m th·∫•y 1 khu√¥n m·∫∑t, ƒëang c·∫Øt ·∫£nh c·∫≠n m·∫∑t...');
    
    // Crop ·∫£nh c·∫≠n m·∫∑t
    const croppedFile = await cropFaceImage(imageFile, detections[0]);
    
    console.log('[Face Detection] ‚úì ƒê√£ c·∫Øt ·∫£nh c·∫≠n m·∫∑t th√†nh c√¥ng');
    
    return {
      success: true,
      file: croppedFile,
      detection: detections[0]
    };
  } catch (error) {
    console.error('[Face Detection] ‚úó L·ªói khi x·ª≠ l√Ω ·∫£nh:', error);
    
    // X·ª≠ l√Ω c√°c lo·∫°i l·ªói c·ª• th·ªÉ
    let errorMessage = 'C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i.';
    
    if (error.message) {
      if (error.message.includes('load face detection models')) {
        errorMessage = '‚ùå Kh√¥ng th·ªÉ t·∫£i models nh·∫≠n di·ªán khu√¥n m·∫∑t.\n\nVui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet v√† th·ª≠ l·∫°i.';
      } else if (error.message.includes('Invalid image file type')) {
        errorMessage = '‚ùå ƒê·ªãnh d·∫°ng ·∫£nh kh√¥ng h·ª£p l·ªá.\n\nVui l√≤ng ch·ªçn file ·∫£nh (JPG, JPEG, PNG, WEBP).';
      } else if (error.message.includes('load ·∫£nh') || error.message.includes('ƒë·ªçc file')) {
        errorMessage = '‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh.\n\nVui l√≤ng ki·ªÉm tra file ·∫£nh c√≥ b·ªã h·ªèng kh√¥ng v√† th·ª≠ l·∫°i.';
      } else {
        errorMessage = `‚ùå L·ªói: ${error.message}\n\nVui l√≤ng th·ª≠ l·∫°i ho·∫∑c ch·ªçn ·∫£nh kh√°c.`;
      }
    }
    
    return {
      success: false,
      error: errorMessage
    };
  }
};

